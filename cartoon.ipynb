{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPEuhcxOxFT60BTTNKvgbWM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zynkchen/Animagine-XL-Lightning-Colab/blob/main/cartoon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç¯å¢ƒåˆå§‹åŒ–ï¼Œç£ç›˜å‡†å¤‡..."
      ],
      "metadata": {
        "id": "OvYo_ZamwRmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. æŒ‚è½½ Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# 2. å®šä¹‰è·¯å¾„\n",
        "# æœ¬åœ°ä¸´æ—¶ç¼“å­˜è·¯å¾„ï¼ˆHugging Face é»˜è®¤ä½ç½®ï¼‰\n",
        "local_cache_path = \"/root/.cache/huggingface/hub\"\n",
        "# äº‘ç›˜æŒä¹…åŒ–å¤§æ–‡ä»¶è·¯å¾„\n",
        "drive_model_path = \"/content/drive/MyDrive/AI_Models_Cache/hub\"\n",
        "\n",
        "os.makedirs(\"/content/drive/MyDrive/AI_Models_Cache\", exist_ok=True)\n",
        "# å®šä¹‰å›¾ç‰‡ä¿å­˜ç›®å½• output_dir\n",
        "output_dir = \"/content/drive/MyDrive/AI_Models_Cache/AI_Pony_Output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 3. æ‰§è¡Œâ€œå«æ¥â€é€»è¾‘\n",
        "if not os.path.exists(local_cache_path):\n",
        "    # å…ˆåˆ›å»ºçˆ¶çº§ç›®å½•\n",
        "    os.makedirs(os.path.dirname(local_cache_path), exist_ok=True)\n",
        "    # å¦‚æœäº‘ç›˜å·²æœ‰å¤‡ä»½ï¼Œåˆ™åˆ›å»ºè½¯é“¾æ¥æ˜ å°„\n",
        "    if os.path.exists(drive_model_path):\n",
        "        print(\"ğŸ”— å‘ç°äº‘ç›˜å·²æœ‰æ¨¡å‹ç¼“å­˜ï¼Œæ­£åœ¨å»ºç«‹è¿æ¥...\")\n",
        "        os.symlink(drive_model_path, local_cache_path)\n",
        "    else:\n",
        "        # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œåˆ›å»ºäº‘ç›˜ç›®å½•å¹¶é“¾æ¥\n",
        "        print(\"ğŸ“ ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œæ­£åœ¨åˆå§‹åŒ–äº‘ç›˜å­˜å‚¨ç©ºé—´...\")\n",
        "        os.makedirs(drive_model_path, exist_ok=True)\n",
        "        os.symlink(drive_model_path, local_cache_path)\n",
        "\n",
        "# 4. å®‰è£…ç¯å¢ƒï¼ˆä¾ç„¶å®‰è£…åœ¨ Colab ä¸´æ—¶ç©ºé—´ï¼Œä¿è¯è¿è¡Œé€Ÿåº¦ï¼‰\n",
        "print(\"âš¡ æ­£åœ¨å®‰è£…æ ¸å¿ƒåº“è‡³ä¸´æ—¶ç©ºé—´...\")\n",
        "# å¼ºåˆ¶åŒæ­¥æ‰€æœ‰æ ¸å¿ƒåº“ç‰ˆæœ¬ï¼Œæ¶ˆé™¤å†²çªæç¤º\n",
        "!pip install -q -U torch torchvision torchaudio diffusers transformers accelerate peft safetensors xformers\n",
        "\n",
        "print(f\"âœ… é…ç½®å®Œæˆï¼\\nğŸš€ å¤§æ–‡ä»¶å°†è‡ªåŠ¨åŒæ­¥è‡³: {drive_model_path}\\nğŸš€ ä¸´æ—¶åº“å’Œå…ƒæ•°æ®ä¿ç•™åœ¨ Colab å†…å­˜åŠ é€Ÿã€‚\")\n",
        "#@title Keep Alive for Mobile Users\n",
        "from IPython.display import Audio,display\n",
        "import numpy as np\n",
        "# è¿™æ˜¯ä¸€ä¸ªé˜²æ­¢ Colab æ–­å¼€è¿æ¥çš„éŸ³é¢‘æ’­æ”¾å™¨\n",
        "display(Audio(np.array([0] * 2 * 3600 * 3000, dtype=np.int8), normalize=False, rate=3000, autoplay=True))"
      ],
      "metadata": {
        "id": "H_mgNDwpwAqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿è¡Œç¯å¢ƒå‡†å¤‡..."
      ],
      "metadata": {
        "id": "qPwjghDbv8UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline, EulerDiscreteScheduler\n",
        "\n",
        "base_model = \"cagliostrolab/animagine-xl-3.1\"\n",
        "lora_model = \"ByteDance/SDXL-Lightning\"\n",
        "\n",
        "print(\"ğŸš€ é‡æ–°å°è¯•åŠ è½½å¼•æ“ï¼ˆé‡‡ç”¨æ›´ç¨³å¥çš„åŠ è½½ç­–ç•¥ï¼‰...\")\n",
        "\n",
        "try:\n",
        "    # 1. åŠ è½½ä¸»æ¨¡å‹\n",
        "    # åˆ é™¤äº† device_map=\"auto\"ï¼Œæ”¹ä¸ºæ˜¾å¼åŠ è½½å .to(\"cuda\")\n",
        "    pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "        base_model,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "\n",
        "    # 2. å°†æ¨¡å‹ç§»è‡³ GPU\n",
        "    pipe.to(\"cuda\")\n",
        "\n",
        "    print(\"ğŸ“¥ åŠ è½½åŠ é€Ÿæ’ä»¶ (Lightning LoRA)...\")\n",
        "    # åŠ è½½ LoRA\n",
        "    pipe.load_lora_weights(lora_model, weight_name=\"sdxl_lightning_4step_lora.safetensors\")\n",
        "    # èåˆ LoRA æƒé‡ä»¥æé«˜æ¨ç†é€Ÿåº¦\n",
        "    pipe.fuse_lora()\n",
        "\n",
        "    # 3. è°ƒåº¦å™¨é…ç½®\n",
        "    pipe.scheduler = EulerDiscreteScheduler.from_config(\n",
        "        pipe.scheduler.config,\n",
        "        timestep_spacing=\"trailing\"\n",
        "    )\n",
        "\n",
        "    # 4. å¼€å¯æé™æ˜¾å­˜ä¼˜åŒ–\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    pipe.enable_vae_tiling()\n",
        "\n",
        "    print(\"âœ… å¼•æ“å°±ç»ªï¼æ¨¡å‹å·²æˆåŠŸéƒ¨ç½²åœ¨ GPUã€‚\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ å†æ¬¡å¤±è´¥ï¼Œé”™è¯¯è¯¦æƒ…: {e}\")\n",
        "    print(\"\\nğŸ’¡ æœ€ç»ˆæ’æŸ¥æ–¹æ¡ˆï¼šå¦‚æœä¾ç„¶æŠ¥é”™ï¼Œè¯·åœ¨å•å…ƒ 1 ä¸­å–æ¶ˆ Google Drive è½¯é“¾æ¥ï¼Œç›´æ¥ä¸‹è½½åˆ° Colab æœ¬åœ°ç©ºé—´æµ‹è¯•ã€‚\")"
      ],
      "metadata": {
        "id": "sJdHCj2mvTWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä¸€æ¬¡ç”Ÿæˆ4å¼ å›¾\n",
        "\n",
        "æ ¸å¿ƒçŠ¶æ€ä¸å§¿åŠ¿ï¼ˆCore Tagsï¼‰\n",
        "\n",
        "    åŸºç¡€è§¦å‘ï¼šnsfw, erotic, suggestive, naked, nude\n",
        "\n",
        "    èº«ä½“ç»†èŠ‚ï¼šdetailed anatomy, realistic skin, skin texture, soft lighting, nipples, pussy, cleavage\n",
        "\n",
        "    åŠ¨ä½œ/çŠ¶æ€ï¼šspreading, legs apart, from behind, bent over, looking at viewer, blush, sweating\n"
      ],
      "metadata": {
        "id": "ESi-Pr1zvL44"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHJOIcSMvEKK"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "import random\n",
        "from IPython.display import display, HTML, update_display\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# ================= åˆ›ä½œæ§åˆ¶é¢æ¿ =================\n",
        "# @markdown ### ğŸŸ¢ æç¤ºè¯è®¾ç½® (Prompt)\n",
        "prompt = \"score_9, score_8_up, score_7_up, source_anime, nsfw, 1girl,  masterpiece, highres, (realistic skin:1.2), (detailed anatomy:1.1), cinemetic lighting, depth of field, erotic, suggestive, naked\" # @param {type:\"string\"}\n",
        "negative_prompt = \"lowres,  deformed, disfigured,lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, artist name\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### ğŸŸ¡ ç”»é¢å‚æ•° (Parameters)\n",
        "num_images = 4 # @param [1, 2, 3, 4] {type:\"raw\"}\n",
        "width = 832 # @param [512, 768, 832, 1024, 1216] {allow-input: true}\n",
        "height = 1216 # @param [512, 768, 832, 1024, 1216] {allow-input: true}\n",
        "steps = 13 # @param {type:\"slider\", min:1, max:20, step:1}\n",
        "cfg_scale = 1.7 # @param {type:\"slider\", min:0.0, max:4.0, step:0.1}\n",
        "\n",
        "# @markdown ### ğŸ”µ éšæœºæ€§æ§åˆ¶ (Seed)\n",
        "seed = -1 # @param {type:\"integer\"}\n",
        "\n",
        "# ================= å®æ—¶å¸ƒå±€é€»è¾‘ =================\n",
        "\n",
        "# 1. åˆå§‹åŒ– HTML ç½‘æ ¼å®¹å™¨\n",
        "grid_id = str(uuid.uuid4())\n",
        "grid_html = f\"\"\"\n",
        "<div id=\"{grid_id}\" style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px; width: 700px;\">\n",
        "    {'<div style=\"aspect-ratio: ' + str(width/height) + '; background: #333; display: flex; align-items: center; justify-content: center; color: #666; font-family: sans-serif;\">Wait...</div>' * num_images}\n",
        "</div>\n",
        "\"\"\"\n",
        "display_handle = display(HTML(grid_html), display_id=grid_id)\n",
        "\n",
        "def img_to_base64(img):\n",
        "    buffered = io.BytesIO()\n",
        "    img.save(buffered, format=\"PNG\")\n",
        "    return base64.b64encode(buffered.getvalue()).decode()\n",
        "\n",
        "positive_prefix = \"masterpiece, best quality, \"\n",
        "all_images_html = [\"\"] * num_images\n",
        "\n",
        "for i in range(num_images):\n",
        "    current_seed = random.randint(0, 1000000) if seed == -1 else seed + i\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(current_seed)\n",
        "\n",
        "    # æ‰§è¡Œæ¨ç†\n",
        "    with torch.inference_mode():\n",
        "        image = pipe(\n",
        "            prompt = positive_prefix + prompt,\n",
        "            negative_prompt = negative_prompt,\n",
        "            num_inference_steps = steps,\n",
        "            guidance_scale = cfg_scale,\n",
        "            width = width,\n",
        "            height = height,\n",
        "            generator = generator\n",
        "        ).images[0]\n",
        "\n",
        "    # ä¿å­˜åŸå›¾\n",
        "    save_path = f\"{output_dir}/anim_s{current_seed}.png\"\n",
        "    image.save(save_path)\n",
        "\n",
        "    # å‡†å¤‡ç¼©ç•¥å›¾é¢„è§ˆ\n",
        "    preview_size = (int(image.width / 3), int(image.height / 3))\n",
        "    preview_img = image.resize(preview_size)\n",
        "    b64_str = img_to_base64(preview_img)\n",
        "\n",
        "    # æ›´æ–° HTML å†…å®¹\n",
        "    all_images_html[i] = f'<div style=\"text-align:center;\"><img src=\"data:image/png;base64,{b64_str}\" style=\"width:100%; border-radius:4px;\"><p style=\"color:#888; font-size:12px;\">Seed: {current_seed}</p></div>'\n",
        "\n",
        "    # å®æ—¶åˆ·æ–°æ˜¾ç¤º\n",
        "    current_grid = f\"\"\"\n",
        "    <div style=\"display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px; width: 700px;\">\n",
        "        {''.join([img_html if img_html else '<div style=\"aspect-ratio: ' + str(width/height) + '; background: #333; display: flex; align-items: center; justify-content: center; color: #999;\">Generating...</div>' for img_html in all_images_html])}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    update_display(HTML(current_grid), display_id=grid_id)\n",
        "\n",
        "print(f\"âœ… ç”Ÿæˆå®Œæ¯•ï¼æ‰€æœ‰é«˜æ¸…å›¾å·²å…¥åº“ã€‚\")"
      ]
    }
  ]
}